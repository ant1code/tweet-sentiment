{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DistilBertSequenceClassification with fine-tuning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPLUlj1jy3k2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab02af51-25dd-4ef3-acdd-58ba77c6b3bc"
      },
      "source": [
        "import tensorflow as tf \n",
        "\n",
        "# check for GPU \n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name == \"/device:GPU:0\":\n",
        "  print(\"Found GPU at {}\".format(device_name))\n",
        "else:\n",
        "  raise SystemError(\"GPU device not found\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyInUja7zYPL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "24959f7e-8cac-4b68-c982-349628d2debf"
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  print(\"There are {} GPU(s) available\".format(torch.cuda.device_count()))\n",
        "  print(\"We will use the GPU\", torch.cuda.get_device_name(0))\n",
        "else: \n",
        "  device = torch.device(\"cpu\")\n",
        "  print(\"No GPU available, we use the CPU instead\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available\n",
            "We will use the GPU Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUTS7nPpzYR9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "9bfc9694-fa79-4a23-fead-9f76402771ce"
      },
      "source": [
        "!pip install transformers \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from transformers import *"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.38)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.41)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.38 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.38)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->transformers) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn5CrUV80Ugc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/ant1code/tweet-sentiment/master/data/train.csv\"\n",
        "df = pd.read_csv(url)[:15000]\n",
        "\n",
        "df.sentiment = pd.Categorical(df.sentiment)\n",
        "df[\"label\"]  = df.sentiment.cat.codes \n",
        "df.drop([\"textID\", \"selected_text\", \"sentiment\"], axis=1, inplace=True)\n",
        "df = df[df.text.notna()]\n",
        "\n",
        "df.text = df.text.str.lower()\n",
        "max_length = max(df.text.apply(len))\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df.text, df.label, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kicWO4tf1jlW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pretrained_weights = \"distilbert-base-uncased\"\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(pretrained_weights, do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vh_t1EMj6_jn",
        "colab": {}
      },
      "source": [
        "token_ids = [] \n",
        "attention_masks = []\n",
        "\n",
        "for text in x_train.values:\n",
        "  encoded_dict = tokenizer.encode_plus(\n",
        "      text, add_special_tokens=True, max_length=max_length,\n",
        "      pad_to_max_length=True, return_attention_mask=True, return_tensors=\"pt\"\n",
        "  )\n",
        "\n",
        "  token_ids.append(encoded_dict[\"input_ids\"])\n",
        "  attention_masks.append(encoded_dict[\"attention_mask\"])\n",
        "\n",
        "token_ids = torch.cat(token_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(y_train.values) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3UmaPAEIUr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split \n",
        "\n",
        "dataset = TensorDataset(token_ids, attention_masks, labels)\n",
        "\n",
        "train_size = int(0.9 * len(dataset))\n",
        "valid_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyrQH1LiK3Rm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size\n",
        ")\n",
        "\n",
        "valid_dataloader = DataLoader(\n",
        "    valid_dataset, sampler=SequentialSampler(valid_dataset), batch_size=batch_size\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAu0wd4eKzjr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2a7169e0-b0fb-488c-f71e-7f243b11303b"
      },
      "source": [
        "model = DistilBertForSequenceClassification.from_pretrained(\n",
        "    pretrained_weights, num_labels=3, output_attentions=False, output_hidden_states=False\n",
        ")\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (1): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (2): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (3): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (4): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (5): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlVUsZNFL865",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62T7fBuwMLAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 4\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer, num_warmup_steps=0, num_training_steps=total_steps\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoxlOwmKManx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time \n",
        "import datetime\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "  pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "  return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def format_time(elapsed):\n",
        "  elapsed_rounded = int(round(elapsed))\n",
        "  return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Goj2FPWO8PA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random \n",
        "\n",
        "seed_val = 10 \n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTq4GLRsPVa0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b7927323-72d8-4c4e-874c-56dbf998edb2"
      },
      "source": [
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        "\n",
        "for epoch_i in range(0, epochs): \n",
        "  print(\"\")\n",
        "  print(\"======= Epoch {:} / {:} =======\".format(epoch_i+1, epochs))\n",
        "  print(\"Training...\")\n",
        "\n",
        "  t0 = time.time()\n",
        "\n",
        "  total_train_loss = 0\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    if step % 40 == 0 and not step == 0:\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "      print(\"  Batch {:>5,} of {:>5,}.    Elapsed: {:}\".format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "      b_input_ids  = batch[0].to(device)\n",
        "      b_input_mask = batch[1].to(device)\n",
        "      b_labels     = batch[2].to(device)\n",
        "\n",
        "      model.zero_grad()\n",
        "\n",
        "      loss, logits = model(\n",
        "          input_ids      = b_input_ids, \n",
        "          attention_mask = b_input_mask, \n",
        "          labels         = b_labels.long()\n",
        "      ) #DistilBertForSequenceClassification does not take in token_type_ids\n",
        "\n",
        "      total_train_loss += loss.item() \n",
        "\n",
        "      loss.backward() \n",
        "\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "      optimizer.step() \n",
        "\n",
        "      scheduler.step() \n",
        "\n",
        "  avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "  \n",
        "  training_time = format_time(time.time() - t0)\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "  print(\"  Training epoch took: {:}\".format(training_time))\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"Running validation...\")\n",
        "\n",
        "  t0 = time.time() \n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  total_eval_accuracy = 0\n",
        "  total_eval_loss = 0 \n",
        "  nb_eval_steps = 0 \n",
        "\n",
        "  for batch in valid_dataloader: \n",
        "    b_input_ids  = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels     = batch[2].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      loss, logits = model(\n",
        "          b_input_ids, attention_mask=b_input_mask, labels=b_labels.long()\n",
        "      ) \n",
        "    \n",
        "    total_eval_loss += loss.item()\n",
        "\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to(\"cpu\").numpy()\n",
        "\n",
        "    total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "\n",
        "  avg_val_accuracy = total_eval_accuracy / len(valid_dataloader)\n",
        "  print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "  avg_val_loss = total_eval_loss / len(valid_dataloader)\n",
        "  print(\"  Validation loss: {0:.2f}\".format(avg_val_loss))\n",
        "  \n",
        "  valid_time = format_time(time.time() - t0)\n",
        "\n",
        "  training_stats.append(\n",
        "      {\n",
        "          \"epoch\": epoch_i+1, \n",
        "          \"training loss\": avg_train_loss, \n",
        "          \"valid. loss\": avg_val_loss, \n",
        "          \"valid. accuracy\": avg_val_accuracy, \n",
        "          \"training time\": training_time, \n",
        "          \"valid. time\": valid_time\n",
        "      }\n",
        "  )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training is complete.\")\n",
        "print(\"Training time: {:}\".format(format_time(time.time() - total_t0)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======= Epoch 1 / 4 =======\n",
            "Training...\n",
            "  Batch    40 of   380.    Elapsed: 0:00:00\n",
            "  Batch    80 of   380.    Elapsed: 0:00:01\n",
            "  Batch   120 of   380.    Elapsed: 0:00:02\n",
            "  Batch   160 of   380.    Elapsed: 0:00:02\n",
            "  Batch   200 of   380.    Elapsed: 0:00:03\n",
            "  Batch   240 of   380.    Elapsed: 0:00:04\n",
            "  Batch   280 of   380.    Elapsed: 0:00:05\n",
            "  Batch   320 of   380.    Elapsed: 0:00:06\n",
            "  Batch   360 of   380.    Elapsed: 0:00:06\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Training epoch took: 0:00:07\n",
            "\n",
            "Running validation...\n",
            "  Accuracy: 0.39\n",
            "  Validation loss: 1.08\n",
            "\n",
            "======= Epoch 2 / 4 =======\n",
            "Training...\n",
            "  Batch    40 of   380.    Elapsed: 0:00:00\n",
            "  Batch    80 of   380.    Elapsed: 0:00:01\n",
            "  Batch   120 of   380.    Elapsed: 0:00:02\n",
            "  Batch   160 of   380.    Elapsed: 0:00:02\n",
            "  Batch   200 of   380.    Elapsed: 0:00:03\n",
            "  Batch   240 of   380.    Elapsed: 0:00:04\n",
            "  Batch   280 of   380.    Elapsed: 0:00:05\n",
            "  Batch   320 of   380.    Elapsed: 0:00:06\n",
            "  Batch   360 of   380.    Elapsed: 0:00:06\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Training epoch took: 0:00:07\n",
            "\n",
            "Running validation...\n",
            "  Accuracy: 0.39\n",
            "  Validation loss: 1.07\n",
            "\n",
            "======= Epoch 3 / 4 =======\n",
            "Training...\n",
            "  Batch    40 of   380.    Elapsed: 0:00:00\n",
            "  Batch    80 of   380.    Elapsed: 0:00:01\n",
            "  Batch   120 of   380.    Elapsed: 0:00:02\n",
            "  Batch   160 of   380.    Elapsed: 0:00:02\n",
            "  Batch   200 of   380.    Elapsed: 0:00:03\n",
            "  Batch   240 of   380.    Elapsed: 0:00:04\n",
            "  Batch   280 of   380.    Elapsed: 0:00:05\n",
            "  Batch   320 of   380.    Elapsed: 0:00:06\n",
            "  Batch   360 of   380.    Elapsed: 0:00:06\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epoch took: 0:00:07\n",
            "\n",
            "Running validation...\n",
            "  Accuracy: 0.46\n",
            "  Validation loss: 1.03\n",
            "\n",
            "======= Epoch 4 / 4 =======\n",
            "Training...\n",
            "  Batch    40 of   380.    Elapsed: 0:00:00\n",
            "  Batch    80 of   380.    Elapsed: 0:00:01\n",
            "  Batch   120 of   380.    Elapsed: 0:00:02\n",
            "  Batch   160 of   380.    Elapsed: 0:00:02\n",
            "  Batch   200 of   380.    Elapsed: 0:00:03\n",
            "  Batch   240 of   380.    Elapsed: 0:00:04\n",
            "  Batch   280 of   380.    Elapsed: 0:00:05\n",
            "  Batch   320 of   380.    Elapsed: 0:00:06\n",
            "  Batch   360 of   380.    Elapsed: 0:00:06\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epoch took: 0:00:07\n",
            "\n",
            "Running validation...\n",
            "  Accuracy: 0.54\n",
            "  Validation loss: 0.94\n",
            "\n",
            "Training is complete.\n",
            "Training time: 0:01:18\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}